
### Akim Mousterou | ムステロ・アキム

**- Master Degree in NLP with Japanese concentration at INALCO**
(I.N.A.L.C.O 東洋言語文化学院、自然言語処理修士 | 卒業)

**- Master Degree in International Business (EMIB) at ESCP Europe**
(ESCPヨーロッパ・ビジネススクール、経営管理修士 | 卒業)

***I have been managing business and digital initiatives for prestigious brands, publishing companies, technology companies, and financial institutions for more than 10 years. Born and raised in Paris, I am fluent in French, English, Japanese (JLPT N2), and Spanish. I am passionate about quantitative finance, network effects, and natural language processing.***

## Project: Open-source RAG for Japanese LLM in low-resource settings

Generative AI for all - Quick implementation with an open-source RAG LlamaIndex and Japanese LLM from ELYZA, Inc. in a low-resource environment over legal documents:
- RAG (retrieval-augmented generation) is LlamaIndex with a vanilla Hybrid search (combining retrieval from both text search and vector search)
- Japanese LLM (large language model) “ELYZA-japanese-Llama-2-7b-instruct” created by Japanese startup, ELYZA, Inc.
- Open-source database PostgreSQL transformed into a vector database by the great library PG Vector
Plus Q&A analysis in Japanese, embedding pricing war, and generative AI strategy of France, USA, and Japan. 

## Project: A fine-tuned XLM-Roberta model for NER in the fashion and luxury industry 
NER-Luxury is a fine-tuned XLM-Roberta model for the subtask N.E.R (Named Entity Recognition) in English. NER-Luxury is domain-specific for the fashion and luxury industry with bespoke labels. NER-Luxury is trying to be a bridge between the aesthetic side and the quantitative side of the fashion and luxury industry.

- 38.063 sentences in English (758.309 words) for 32 labels
- XLM-Roberta from Meta A.I (Facebook)
- AI Framework: PyTorch version 2.0.1+cu118
- Transformers version 4.35.0 from Hugging Face : )

https://huggingface.co/AkimfromParis/NER-Luxury

## Project: 
